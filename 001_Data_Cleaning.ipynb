{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beijing Air-Quality Time Series Project\n",
    "### Data Cleaning Notebook\n",
    "\n",
    "by Dolci Sanders and Paul Torres\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data\n",
    "\n",
    "Our Data is provided by the UCI Machine Learning Repository\n",
    "Beijing Multi-Site Air-Quality Data\n",
    "\n",
    "Once Read in, we will look at the head and convert our time into data time. \n",
    "\n",
    "We have 12 data sets, one from each reporting site, to concatenate together to get the whole picture of Beijing's Air Quality. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = pd.read_csv('DATA/PRSA_Data_Tiantan_20130301-20170228.csv', index_col = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>SO2</th>\n",
       "      <th>NO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>O3</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>RAIN</th>\n",
       "      <th>wd</th>\n",
       "      <th>WSPM</th>\n",
       "      <th>station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1024.5</td>\n",
       "      <td>-21.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>5.7</td>\n",
       "      <td>Tiantan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>1025.1</td>\n",
       "      <td>-22.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Tiantan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>1025.3</td>\n",
       "      <td>-24.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>5.3</td>\n",
       "      <td>Tiantan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>1026.2</td>\n",
       "      <td>-25.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Tiantan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>1027.1</td>\n",
       "      <td>-24.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Tiantan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  year  month  day  hour  PM2.5  PM10  SO2   NO2     CO    O3  TEMP  \\\n",
       "0   1  2013      3    1     0    6.0   6.0  4.0   8.0  300.0  81.0  -0.5   \n",
       "1   2  2013      3    1     1    6.0  29.0  5.0   9.0  300.0  80.0  -0.7   \n",
       "2   3  2013      3    1     2    6.0   6.0  4.0  12.0  300.0  75.0  -1.2   \n",
       "3   4  2013      3    1     3    6.0   6.0  4.0  12.0  300.0  74.0  -1.4   \n",
       "4   5  2013      3    1     4    5.0   5.0  7.0  15.0  400.0  70.0  -1.9   \n",
       "\n",
       "     PRES  DEWP  RAIN   wd  WSPM  station  \n",
       "0  1024.5 -21.4   0.0  NNW   5.7  Tiantan  \n",
       "1  1025.1 -22.1   0.0   NW   3.9  Tiantan  \n",
       "2  1025.3 -24.6   0.0  NNW   5.3  Tiantan  \n",
       "3  1026.2 -25.5   0.0    N   4.9  Tiantan  \n",
       "4  1027.1 -24.5   0.0  NNW   3.2  Tiantan  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Time Formatting\n",
    "Crucial to time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time['Date'] = pd.to_datetime(time[['year','month','day','hour']])\n",
    "time = time.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35064, 18)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Nan Values\n",
    "After looking at the data, we wanted to look at null values and figure out what to do with these. \n",
    "\n",
    "We first calculated the mean and media for all of the values. These values varied wildly and we were concerned they would have a negative effect on the predictions. \n",
    "\n",
    "However, upon further research, other methods have proven more effective in inputing the data for time series such as Interpolating Time, however because we have hourly time this was not the best method. We elected to try imputing using the InterpolateLinear method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No            0\n",
       "year          0\n",
       "month         0\n",
       "day           0\n",
       "hour          0\n",
       "PM2.5       677\n",
       "PM10        597\n",
       "SO2        1118\n",
       "NO2         744\n",
       "CO         1126\n",
       "O3          843\n",
       "TEMP         20\n",
       "PRES         20\n",
       "DEWP         20\n",
       "RAIN         20\n",
       "wd           78\n",
       "WSPM         14\n",
       "station       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = time.interpolate(method='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PM2.5 (TARGET VARIABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total PM2.5 Missing Values:  0\n",
      "mean:  82.03309662331738\n",
      "median:  58.0\n"
     ]
    }
   ],
   "source": [
    "print('total PM2.5 Missing Values: ', time['PM2.5'].isna().sum())\n",
    "print('mean: ', time['PM2.5'].mean())\n",
    "print('median: ', time['PM2.5'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PM10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total PM10 Missing Values:  0\n",
      "mean:  106.53707648870636\n",
      "median:  85.0\n"
     ]
    }
   ],
   "source": [
    "print('total PM10 Missing Values: ', time['PM10'].isna().sum())\n",
    "print('mean: ', time['PM10'].mean())\n",
    "print('median: ', time['PM10'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total SO2 Missing Values:  0\n",
      "mean:  14.510017738991555\n",
      "median:  7.0\n"
     ]
    }
   ],
   "source": [
    "print('total SO2 Missing Values: ', time['SO2'].isna().sum())\n",
    "print('mean: ', time['SO2'].mean())\n",
    "print('median: ', time['SO2'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total NO2 Missing Values:  0\n",
      "mean:  53.25882833532967\n",
      "median:  47.0\n"
     ]
    }
   ],
   "source": [
    "print('total NO2 Missing Values: ', time['NO2'].isna().sum())\n",
    "print('mean: ', time['NO2'].mean())\n",
    "print('median: ', time['NO2'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total CO Missing Values:  0\n",
      "mean:  1305.3332620351357\n",
      "median:  900.0\n"
     ]
    }
   ],
   "source": [
    "print('total CO Missing Values: ', time['CO'].isna().sum())\n",
    "print('mean: ', time['CO'].mean())\n",
    "print('median: ', time['CO'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total O3 Missing Values:  0\n",
      "mean:  56.14807717887289\n",
      "median:  40.0\n"
     ]
    }
   ],
   "source": [
    "print('total O3 Missing Values: ', time['O3'].isna().sum())\n",
    "print('mean: ', time['O3'].mean())\n",
    "print('median: ', time['O3'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total TEMP Missing Values:  0\n",
      "mean:  13.668249517775271\n",
      "median:  14.6\n"
     ]
    }
   ],
   "source": [
    "print('total TEMP Missing Values: ', time['TEMP'].isna().sum())\n",
    "print('mean: ', time['TEMP'].mean())\n",
    "print('median: ', time['TEMP'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total PRES Missing Values:  0\n",
      "mean:  1012.5518711023906\n",
      "median:  1012.2\n"
     ]
    }
   ],
   "source": [
    "print('total PRES Missing Values: ', time['PRES'].isna().sum())\n",
    "print('mean: ', time['PRES'].mean())\n",
    "print('median: ', time['PRES'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEWP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total DEWP Missing Values:  0\n",
      "mean:  2.4451260552133287\n",
      "median:  3.0\n"
     ]
    }
   ],
   "source": [
    "print('total DEWP Missing Values: ', time['DEWP'].isna().sum())\n",
    "print('mean: ', time['DEWP'].mean())\n",
    "print('median: ', time['DEWP'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total RAIN Missing Values:  0\n",
      "mean:  0.06398300250969628\n",
      "median:  0.0\n"
     ]
    }
   ],
   "source": [
    "print('total RAIN Missing Values: ', time['RAIN'].isna().sum())\n",
    "print('mean: ', time['RAIN'].mean())\n",
    "print('median: ', time['RAIN'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wd\n",
    "\n",
    "wd is wind direction and is not an integer. We will forward fill the missing values. As wind direction does not change rapidly. --A few of these (4) did not change from nan's and for those stuborn nan values, we used back fill for these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.wd = time.wd.fillna(method = 'ffill')\n",
    "time.wd = time.wd.fillna(method = 'bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WSPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total WSPM Missing Values:  0\n",
      "mean:  1.8608145106091456\n",
      "median:  1.5\n"
     ]
    }
   ],
   "source": [
    "print('total WSPM Missing Values: ', time['WSPM'].isna().sum())\n",
    "print('mean: ', time['WSPM'].mean())\n",
    "print('median: ', time['WSPM'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nan Values Filled, check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No         0\n",
       "year       0\n",
       "month      0\n",
       "day        0\n",
       "hour       0\n",
       "PM2.5      0\n",
       "PM10       0\n",
       "SO2        0\n",
       "NO2        0\n",
       "CO         0\n",
       "O3         0\n",
       "TEMP       0\n",
       "PRES       0\n",
       "DEWP       0\n",
       "RAIN       0\n",
       "wd         0\n",
       "WSPM       0\n",
       "station    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine 12 Testing Site Tables\n",
    "We have 12 testing sites with a table for each. \n",
    "So we built a function to automate our concatenation of all of these. \n",
    "For each test site, we loop through these, train test split, interpolate the test then the train using the time method, \n",
    "finally we back fill the stubborn few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the DATA folder, we wil run through all of the individual csv files. \n",
    "\n",
    "path = r'DATA/' \n",
    "allFiles = glob.glob(path + '/*.csv')\n",
    "\n",
    "# Prep the test and train data frames. \n",
    "train = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "\n",
    "trains = []\n",
    "tests = []\n",
    "\n",
    "for file_ in allFiles:\n",
    "    \n",
    "    # Read in and set data index. \n",
    "    df = pd.read_csv(file_,index_col = None,header = 0)\n",
    "    df['Date'] = pd.to_datetime(df[['year','month','day','hour']])\n",
    "    df = df.set_index('Date')\n",
    "    \n",
    "    # Drop unwanted columns \n",
    "    \n",
    "    X = df.drop(columns=['PM2.5','year','month','day','hour','No'], axis = 1)\n",
    "    \n",
    "    # Set the target \n",
    "    \n",
    "    y = df['PM2.5']\n",
    "    \n",
    "    # Train test split to prevent data leakage\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Here we take the X and Y to combine into a train DF and a test DF\n",
    "    \n",
    "    train = pd.concat([X_train,y_train], axis = 1, ignore_index=True)\n",
    "    train.columns = ['PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN','wd', 'WSPM', 'station','PM2.5']\n",
    "    \n",
    "    test = pd.concat([X_test,y_test], axis = 1, ignore_index=True)\n",
    "    test.columns = ['PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN','wd', 'WSPM', 'station','PM2.5']\n",
    "    \n",
    "    # Interpolate the train data and add to the rest of the train list \n",
    "    \n",
    "    train = train.interpolate(method = 'time')\n",
    "    train.wd = train.wd.fillna(method = 'ffill')\n",
    "    trains.append(train)\n",
    "    \n",
    "    # Interpolate the test data and add to the rest of the test list \n",
    "    \n",
    "    test = test.interpolate(method = 'time')\n",
    "    test.wd = test.wd.fillna(method = 'ffill')\n",
    "    test.O3 = test.O3.fillna(method = 'bfill')\n",
    "    test.CO = test.CO.fillna(method = 'bfill')\n",
    "    tests.append(test)\n",
    "    \n",
    "# Take the data fame we made at the top and combine the new data frame we processed here \n",
    "    \n",
    "train = pd.concat(trains)\n",
    "train = train.sort_values(['station', 'Date'])\n",
    "test = pd.concat(tests)\n",
    "test = test.sort_values(['station', 'Date'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle the Train and Test Data, then proceed to the EDA Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_pickle('PKL/test.pkl')\n",
    "train.to_pickle('PKL/train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
